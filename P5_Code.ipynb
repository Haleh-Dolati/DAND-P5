{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Haleh/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from tester import dump_classifier_and_data\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "import pylab as pl\n",
    "from feature_format import featureFormat\n",
    "from feature_format import targetFeatureSplit\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load poi_id.py\n",
    "#!/usr/bin/python\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['METTS MARK',\n",
      " 'BAXTER JOHN C',\n",
      " 'ELLIOTT STEVEN',\n",
      " 'CORDES WILLIAM R',\n",
      " 'HANNON KEVIN P',\n",
      " 'MORDAUNT KRISTINA M',\n",
      " 'MEYER ROCKFORD G',\n",
      " 'MCMAHON JEFFREY',\n",
      " 'HORTON STANLEY C',\n",
      " 'PIPER GREGORY F',\n",
      " 'HUMPHREY GENE E',\n",
      " 'UMANOFF ADAM S',\n",
      " 'BLACHMAN JEREMY M',\n",
      " 'SUNDE MARTIN',\n",
      " 'GIBBS DANA R',\n",
      " 'LOWRY CHARLES P',\n",
      " 'COLWELL WESLEY',\n",
      " 'MULLER MARK S',\n",
      " 'JACKSON CHARLENE R',\n",
      " 'WESTFAHL RICHARD K',\n",
      " 'WALTERS GARETH W',\n",
      " 'WALLS JR ROBERT H',\n",
      " 'KITCHEN LOUISE',\n",
      " 'CHAN RONNIE',\n",
      " 'BELFER ROBERT',\n",
      " 'SHANKMAN JEFFREY A',\n",
      " 'WODRASKA JOHN',\n",
      " 'BERGSIEKER RICHARD P',\n",
      " 'URQUHART JOHN A',\n",
      " 'BIBI PHILIPPE A',\n",
      " 'RIEKER PAULA H',\n",
      " 'WHALEY DAVID A',\n",
      " 'BECK SALLY W',\n",
      " 'HAUG DAVID L',\n",
      " 'ECHOLS JOHN B',\n",
      " 'MENDELSOHN JOHN',\n",
      " 'HICKERSON GARY J',\n",
      " 'CLINE KENNETH W',\n",
      " 'LEWIS RICHARD',\n",
      " 'HAYES ROBERT E',\n",
      " 'MCCARTY DANNY J',\n",
      " 'KOPPER MICHAEL J',\n",
      " 'LEFF DANIEL P',\n",
      " 'LAVORATO JOHN J',\n",
      " 'BERBERIAN DAVID',\n",
      " 'DETMERING TIMOTHY J',\n",
      " 'WAKEHAM JOHN',\n",
      " 'POWERS WILLIAM',\n",
      " 'GOLD JOSEPH',\n",
      " 'BANNANTINE JAMES M',\n",
      " 'DUNCAN JOHN H',\n",
      " 'SHAPIRO RICHARD S',\n",
      " 'SHERRIFF JOHN R',\n",
      " 'SHELBY REX',\n",
      " 'LEMAISTRE CHARLES',\n",
      " 'DEFFNER JOSEPH M',\n",
      " 'KISHKILL JOSEPH G',\n",
      " 'WHALLEY LAWRENCE G',\n",
      " 'MCCONNELL MICHAEL S',\n",
      " 'PIRO JIM',\n",
      " 'DELAINEY DAVID W',\n",
      " 'SULLIVAN-SHAKLOVITZ COLLEEN',\n",
      " 'WROBEL BRUCE',\n",
      " 'LINDHOLM TOD A',\n",
      " 'MEYER JEROME J',\n",
      " 'LAY KENNETH L',\n",
      " 'BUTTS ROBERT H',\n",
      " 'OLSON CINDY K',\n",
      " 'MCDONALD REBECCA',\n",
      " 'CUMBERLAND MICHAEL S',\n",
      " 'GAHN ROBERT S',\n",
      " 'MCCLELLAN GEORGE',\n",
      " 'HERMANN ROBERT J',\n",
      " 'SCRIMSHAW MATTHEW',\n",
      " 'GATHMANN WILLIAM D',\n",
      " 'HAEDICKE MARK E',\n",
      " 'BOWEN JR RAYMOND M',\n",
      " 'GILLIS JOHN',\n",
      " 'FITZGERALD JAY L',\n",
      " 'MORAN MICHAEL P',\n",
      " 'REDMOND BRIAN L',\n",
      " 'BAZELIDES PHILIP J',\n",
      " 'BELDEN TIMOTHY N',\n",
      " 'DURAN WILLIAM D',\n",
      " 'THORN TERENCE H',\n",
      " 'FASTOW ANDREW S',\n",
      " 'FOY JOE',\n",
      " 'CALGER CHRISTOPHER F',\n",
      " 'RICE KENNETH D',\n",
      " 'KAMINSKI WINCENTY J',\n",
      " 'LOCKHART EUGENE E',\n",
      " 'COX DAVID',\n",
      " 'OVERDYKE JR JERE C',\n",
      " 'PEREIRA PAULO V. FERRAZ',\n",
      " 'STABLER FRANK',\n",
      " 'SKILLING JEFFREY K',\n",
      " 'BLAKE JR. NORMAN P',\n",
      " 'SHERRICK JEFFREY B',\n",
      " 'PRENTICE JAMES',\n",
      " 'GRAY RODNEY',\n",
      " 'PICKERING MARK R',\n",
      " 'THE TRAVEL AGENCY IN THE PARK',\n",
      " 'NOLES JAMES L',\n",
      " 'KEAN STEVEN J',\n",
      " 'TOTAL',\n",
      " 'FOWLER PEGGY',\n",
      " 'WASAFF GEORGE',\n",
      " 'WHITE JR THOMAS E',\n",
      " 'CHRISTODOULOU DIOMEDES',\n",
      " 'ALLEN PHILLIP K',\n",
      " 'SHARP VICTORIA T',\n",
      " 'JAEDICKE ROBERT',\n",
      " 'WINOKUR JR. HERBERT S',\n",
      " 'BROWN MICHAEL',\n",
      " 'BADUM JAMES P',\n",
      " 'HUGHES JAMES A',\n",
      " 'REYNOLDS LAWRENCE',\n",
      " 'DIMICHELE RICHARD G',\n",
      " 'BHATNAGAR SANJAY',\n",
      " 'CARTER REBECCA C',\n",
      " 'BUCHANAN HAROLD G',\n",
      " 'YEAP SOON',\n",
      " 'MURRAY JULIA H',\n",
      " 'GARLAND C KEVIN',\n",
      " 'DODSON KEITH',\n",
      " 'YEAGER F SCOTT',\n",
      " 'HIRKO JOSEPH',\n",
      " 'DIETRICH JANET R',\n",
      " 'DERRICK JR. JAMES V',\n",
      " 'FREVERT MARK A',\n",
      " 'PAI LOU L',\n",
      " 'BAY FRANKLIN R',\n",
      " 'HAYSLETT RODERICK J',\n",
      " 'FUGH JOHN L',\n",
      " 'FALLON JAMES B',\n",
      " 'KOENIG MARK E',\n",
      " 'SAVAGE FRANK',\n",
      " 'IZZO LAWRENCE L',\n",
      " 'TILNEY ELIZABETH A',\n",
      " 'MARTIN AMANDA K',\n",
      " 'BUY RICHARD B',\n",
      " 'GRAMM WENDY L',\n",
      " 'CAUSEY RICHARD A',\n",
      " 'TAYLOR MITCHELL S',\n",
      " 'DONAHUE JR JEFFREY M',\n",
      " 'GLISAN JR BEN F']\n",
      "('There are ', 146, ' executives in Enron Dataset.')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint (data_dict.keys())\n",
    "print (\"There are \", len(data_dict.keys()), \" executives in Enron Dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Select what features you'll use.\n",
    "features_list is a list of strings, each of which is a feature name.<br>\n",
    "The first feature must be \"poi\".<br>\n",
    "You will need to use more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Task 1: Select what features you'll use.\n",
    "\n",
    "features_list = ['poi',\n",
    "                 'bonus',\n",
    "                 'salary',\n",
    "                 'salary_to_avg',\n",
    "                 'deferral_payments',\n",
    "                 'total_payments',\n",
    "                 'restricted_stock_deferred',\n",
    "                 'exercised_stock_options',\n",
    "                 'from_poi_to_this_person',\n",
    "                 'from_this_person_to_poi']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Remove outliers\n",
    "based on mini-project in outlier lessons, i know there is a key \"Total\", which holds the total value for all other values. <br>\n",
    "Another one is the key \"THE TRAVEL AGENCY IN THE PARK\".<br>\n",
    "I'm going to exclude both of them\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bonus': 97343619,\n",
      " 'deferral_payments': 32083396,\n",
      " 'deferred_income': -27992891,\n",
      " 'director_fees': 1398517,\n",
      " 'email_address': 'NaN',\n",
      " 'exercised_stock_options': 311764000,\n",
      " 'expenses': 5235198,\n",
      " 'from_messages': 'NaN',\n",
      " 'from_poi_to_this_person': 'NaN',\n",
      " 'from_this_person_to_poi': 'NaN',\n",
      " 'loan_advances': 83925000,\n",
      " 'long_term_incentive': 48521928,\n",
      " 'other': 42667589,\n",
      " 'poi': False,\n",
      " 'restricted_stock': 130322299,\n",
      " 'restricted_stock_deferred': -7576788,\n",
      " 'salary': 26704229,\n",
      " 'shared_receipt_with_poi': 'NaN',\n",
      " 'to_messages': 'NaN',\n",
      " 'total_payments': 309886585,\n",
      " 'total_stock_value': 434509511}\n",
      "{'bonus': 'NaN',\n",
      " 'deferral_payments': 'NaN',\n",
      " 'deferred_income': 'NaN',\n",
      " 'director_fees': 'NaN',\n",
      " 'email_address': 'NaN',\n",
      " 'exercised_stock_options': 'NaN',\n",
      " 'expenses': 'NaN',\n",
      " 'from_messages': 'NaN',\n",
      " 'from_poi_to_this_person': 'NaN',\n",
      " 'from_this_person_to_poi': 'NaN',\n",
      " 'loan_advances': 'NaN',\n",
      " 'long_term_incentive': 'NaN',\n",
      " 'other': 362096,\n",
      " 'poi': False,\n",
      " 'restricted_stock': 'NaN',\n",
      " 'restricted_stock_deferred': 'NaN',\n",
      " 'salary': 'NaN',\n",
      " 'shared_receipt_with_poi': 'NaN',\n",
      " 'to_messages': 'NaN',\n",
      " 'total_payments': 362096,\n",
      " 'total_stock_value': 'NaN'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint (data_dict[\"TOTAL\"], width=1)\n",
    "pprint.pprint (data_dict[\"THE TRAVEL AGENCY IN THE PARK\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 'NaN',\n",
       " 'deferral_payments': 'NaN',\n",
       " 'deferred_income': 'NaN',\n",
       " 'director_fees': 'NaN',\n",
       " 'email_address': 'NaN',\n",
       " 'exercised_stock_options': 'NaN',\n",
       " 'expenses': 'NaN',\n",
       " 'from_messages': 'NaN',\n",
       " 'from_poi_to_this_person': 'NaN',\n",
       " 'from_this_person_to_poi': 'NaN',\n",
       " 'loan_advances': 'NaN',\n",
       " 'long_term_incentive': 'NaN',\n",
       " 'other': 362096,\n",
       " 'poi': False,\n",
       " 'restricted_stock': 'NaN',\n",
       " 'restricted_stock_deferred': 'NaN',\n",
       " 'salary': 'NaN',\n",
       " 'shared_receipt_with_poi': 'NaN',\n",
       " 'to_messages': 'NaN',\n",
       " 'total_payments': 362096,\n",
       " 'total_stock_value': 'NaN'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict.pop(\"TOTAL\")\n",
    "data_dict.pop(\"THE TRAVEL AGENCY IN THE PARK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Create new feature(s)\n",
    "Store to my_dataset for easy export below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284087.542553\n"
     ]
    }
   ],
   "source": [
    "total = 0.0\n",
    "avg=0.0\n",
    "for k,v in data_dict.iteritems():\n",
    "    if v['salary'] == \"NaN\" or v['salary']<0:\n",
    "        v['salary_to_avg'] = \"NaN\"\n",
    "    else:\n",
    "        total += v['salary']\n",
    "avg= total/94        \n",
    "print avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key, value in data_dict.iteritems():\n",
    "    if value[\"salary\"] == \"NaN\" :\n",
    "        value['salary_to_avg'] = \"NaN\"\n",
    "    else:\n",
    "        value['salary_to_avg'] = float(value['salary']) / float(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for k,v in data_dict.iteritems():\n",
    "#     print v['salary_to_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_dataset = data_dict\n",
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 144 entries, ALLEN PHILLIP K to YEAP SOON\n",
      "Data columns (total 10 columns):\n",
      "poi                          144 non-null bool\n",
      "bonus                        81 non-null float64\n",
      "salary                       94 non-null float64\n",
      "salary_to_avg                94 non-null float64\n",
      "deferral_payments            38 non-null float64\n",
      "total_payments               123 non-null float64\n",
      "restricted_stock_deferred    17 non-null float64\n",
      "exercised_stock_options      101 non-null float64\n",
      "from_poi_to_this_person      86 non-null float64\n",
      "from_this_person_to_poi      86 non-null float64\n",
      "dtypes: bool(1), float64(9)\n",
      "memory usage: 11.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(my_dataset, orient = 'index')\n",
    "df = df[features_list]\n",
    "df = df.replace('NaN', np.nan)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Provided to give you a starting point. Try a variety of classifiers.\n",
    "\n",
    "data = featureFormat(my_dataset, features_list)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels,  \n",
    "                                                                            test_size=0.2, random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.275862068966 0.16 1.0\n"
     ]
    }
   ],
   "source": [
    "clf_GNB = GaussianNB()\n",
    "model_GNB = clf_GNB.fit(features_train, labels_train) \n",
    "pred_GNB = model_GNB.predict(features_test)\n",
    "acc_GNB= accuracy_score(pred_GNB, labels_test)\n",
    "recall_GNB = metrics.recall_score(pred_GNB,labels_test)\n",
    "precision_GNB = metrics.precision_score(pred_GNB,labels_test)\n",
    "\n",
    "print acc_GNB, recall_GNB, precision_GNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.827586206897 0.333333333333 0.25\n"
     ]
    }
   ],
   "source": [
    "clf_knc = KNeighborsClassifier()\n",
    "model_knc = clf_knc.fit(features_train, labels_train) \n",
    "pred_knc = model_knc.predict(features_test)\n",
    "acc_knc= accuracy_score(pred_knc, labels_test)\n",
    "recall = metrics.recall_score(pred_knc,labels_test)\n",
    "precision = metrics.precision_score(pred_knc,labels_test)\n",
    "\n",
    "print acc_knc, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.827586206897 0.4 0.5\n"
     ]
    }
   ],
   "source": [
    "clf_dt = DecisionTreeClassifier(splitter='best', random_state=42)\n",
    "clf_dt = clf_dt.fit(features_train, labels_train) \n",
    "pred_dt = clf_dt.predict(features_test)\n",
    "acc_dt= accuracy_score(pred_dt, labels_test)\n",
    "recall_dt = metrics.recall_score(pred_dt,labels_test)\n",
    "precision_dt = metrics.precision_score(pred_dt,labels_test)\n",
    "\n",
    "print acc_dt, recall_dt, precision_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e66aca0b06f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#gridsearch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mgrid_KNC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe_KNC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid_KNC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'recall'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mgs_KNC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_KNC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mclf_KNC\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mgs_KNC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mclf_KNC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Haleh/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Haleh/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Haleh/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Haleh/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m             \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchedCalls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m                 \u001b[0;31m# No more tasks available in the iterator: tell caller to stop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Haleh/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, iterator_slice)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Haleh/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m((parameters,))\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    564\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m           for train, test in cv_iter)\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Haleh/anaconda/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mnew_object_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mnew_object_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mnew_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mparams_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Haleh/anaconda/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# XXX: not handling dictionaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mestimator_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mestimator_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_params'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Haleh/anaconda/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# XXX: not handling dictionaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mestimator_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mestimator_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_params'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Haleh/anaconda/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mnew_object_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mnew_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mparams_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# quick sanity check of the parameters of the clone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Haleh/anaconda/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \"\"\"\n\u001b[1;32m    234\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m             \u001b[0;31m# We need deprecation warnings to always be on in order to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;31m# catch deprecated param values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Haleh/anaconda/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36m_get_param_names\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;31m# introspect the constructor arguments to find the model parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;31m# to represent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0minit_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         parameters = [p for p in init_signature.parameters.values()\n",
      "\u001b[0;32m/Users/Haleh/anaconda/lib/python2.7/site-packages/sklearn/externals/funcsigs.pyc\u001b[0m in \u001b[0;36msignature\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;31m# Unbound method: the first parameter becomes positional-only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 first = sig.parameters.values()[0].replace(\n\u001b[0m\u001b[1;32m     67\u001b[0m                     kind=_POSITIONAL_ONLY)\n\u001b[1;32m     68\u001b[0m                 return sig.replace(\n",
      "\u001b[0;32m/Users/Haleh/anaconda/lib/python2.7/site-packages/sklearn/externals/funcsigs.pyc\u001b[0m in \u001b[0;36mparameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMappingProxyType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Haleh/anaconda/lib/python2.7/collections.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_setitem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setitem__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Haleh/anaconda/lib/python2.7/_abcoll.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Haleh/anaconda/lib/python2.7/collections.pyc\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value, dict_setitem)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mlast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mlast\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdict_setitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__delitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_delitem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__delitem__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Creat the pipeline\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=100, random_state = 42)\n",
    "pipe_KNC = Pipeline([\n",
    "    ('reduce_dim', SelectKBest()),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('classify', KNeighborsClassifier())\n",
    "])\n",
    "param_grid_KNC = [\n",
    "    {\n",
    "        'reduce_dim__k': [3, 6, 9],\n",
    "        'classify__algorithm' : ['auto'], \n",
    "        'classify__leaf_size' : [30, 50],\n",
    "        'classify__n_neighbors' : [5, 10], \n",
    "        'classify__p' : [1, 2], \n",
    "        'classify__weights' : ['uniform', 'distance'],\n",
    "        'classify__algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "    },\n",
    "]\n",
    "\n",
    "#gridsearch\n",
    "grid_KNC = GridSearchCV(pipe_KNC, cv=sss, param_grid=param_grid_KNC, scoring='recall')\n",
    "gs_KNC = grid_KNC.fit(features, labels)\n",
    "clf_KNC =gs_KNC.best_estimator_\n",
    "print clf_KNC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dump_classifier_and_data(clf_KNC, my_dataset, features_list)\n",
    "from tester import dump_classifier_and_data, test_classifier\n",
    "test_classifier(clf_KNC, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Creat the pipeline\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=100, random_state = 42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('reduce_dim', SelectKBest()),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('classify', DecisionTreeClassifier(splitter='best', random_state=42))\n",
    "])\n",
    "\n",
    "param_grid_DT = [\n",
    "    {\n",
    "        'reduce_dim__k': [3,6,9],\n",
    "        'classify__criterion':['gini', 'entropy'],\n",
    "        'classify__class_weight':[None, 'balanced'],\n",
    "        'classify__min_samples_split' : [2,3,4,5],\n",
    "        'classify__max_leaf_nodes': [None, 5],\n",
    "        'classify__min_samples_leaf': [4, 2]\n",
    "    },\n",
    "]\n",
    "\n",
    "gs_DT = GridSearchCV(pipe, cv=sss, param_grid=param_grid_DT, scoring='f1')\n",
    "gs_DT.fit(features, labels)\n",
    "clf_DT =gs_DT.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finalFeatureIndices_DT = gs_DT.best_estimator_.named_steps[\"reduce_dim\"].get_support(indices = True)\n",
    "finalFeatureList_DT = [features_list[i+1] for i in finalFeatureIndices_DT]\n",
    "print finalFeatureList_DT\n",
    "\n",
    "# importance_DT = gs_DT.feature_importances_.named_steps[\"classify\"]\n",
    "importance_DT = gs_DT.best_estimator_.named_steps[\"classify\"].feature_importances_\n",
    "print importance_DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dump_classifier_and_data(clf_DT, my_dataset, features_list)\n",
    "from tester import dump_classifier_and_data, test_classifier\n",
    "test_classifier(clf_DT, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
